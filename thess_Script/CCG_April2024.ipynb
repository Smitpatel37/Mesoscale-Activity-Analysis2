{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761536d5-4eaa-4852-a082-f2cc605420a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO, NWBFile, TimeSeries\n",
    "from pynwb.behavior import Position, SpatialSeries\n",
    "from pynwb.epoch import TimeIntervals\n",
    "from pynwb.file import Subject\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from itertools import count\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6bf9ac75-823c-4d4d-9dd8-754189073f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "### Get times and clean data\n",
    "\n",
    "\n",
    "def Clean_data(file, alltrials):\n",
    "    with NWBHDF5IO(file, \"r\") as io:\n",
    "\n",
    "        read_nwbfile = io.read()\n",
    "        pre_start = read_nwbfile.acquisition[\"BehavioralEvents\"][\"presample_start_times\"].timestamps[:]\n",
    "        pre_stop = read_nwbfile.acquisition[\"BehavioralEvents\"][\"presample_stop_times\"].timestamps[:]\n",
    "        sample_start = read_nwbfile.acquisition[\"BehavioralEvents\"][\"sample_start_times\"].timestamps[:]\n",
    "        sample_stop = read_nwbfile.acquisition[\"BehavioralEvents\"][\"sample_stop_times\"].timestamps[:]\n",
    "        delay_start = read_nwbfile.acquisition[\"BehavioralEvents\"][\"delay_start_times\"].timestamps[:]\n",
    "        delay_stop = read_nwbfile.acquisition[\"BehavioralEvents\"][\"delay_stop_times\"].timestamps[:]\n",
    "        go_start = read_nwbfile.acquisition[\"BehavioralEvents\"][\"go_start_times\"].timestamps[:]\n",
    "        go_stop = read_nwbfile.acquisition[\"BehavioralEvents\"][\"go_stop_times\"].timestamps[:]\n",
    "    \n",
    "    sample_start = np.intersect1d(pre_stop, sample_start)\n",
    "    sample_stop = np.intersect1d(sample_stop, delay_start)\n",
    "    delay_start = np.intersect1d(delay_start, sample_stop)\n",
    "    delay_stop = np.intersect1d(delay_stop, go_start)\n",
    "    # Add epoch's Start-Stop time pair to each trial\n",
    "    alltrials_clean = alltrials.assign(pre_start = pre_start,\n",
    "                             pre_stop = pre_stop,\n",
    "                             sample_start = sample_start,\n",
    "                             sample_stop = sample_stop,\n",
    "                             delay_start = delay_start,\n",
    "                             delay_stop = delay_stop,\n",
    "                             go_start = go_start,\n",
    "                             go_stop = go_stop)\n",
    "    return alltrials_clean\n",
    "\n",
    "\n",
    "def select_units(units, region):\n",
    "    ### unit specification (specify region, only good units, etc)\n",
    "    units['Region'] = units.electrodes.apply(lambda x: ast.literal_eval(x.location.values[0])['brain_regions']) ## adds column \"Region\"\n",
    "    units_Data = units.query(f\" Region == '{region}' \")\n",
    "    units_Data = units_Data.query(\" unit_quality == 'good'\")\n",
    "    return units_Data\n",
    "def select_trials(alltrials_clean):\n",
    "    #### trial specification (e.g., only hit, no early, etc)\n",
    "    trials_Data = alltrials_clean.query(\"outcome == 'hit' \")\n",
    "    trials_Data = trials_Data.query(\"early_lick == 'no early'\")\n",
    "    return trials_Data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e9cc224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456772\n",
      "sub-455219_ses-20190805T152117_behavior+ecephys+ogen.nwb\n",
      "left ALM          524\n",
      "left Thalamus     505\n",
      "right ALM         375\n",
      "right Midbrain    296\n",
      "Name: electrodes, dtype: int64\n",
      "sub-455219_ses-20190807T134913_behavior+ecephys+ogen.nwb\n",
      "right ALM         676\n",
      "left ALM          409\n",
      "right Midbrain    342\n",
      "Name: electrodes, dtype: int64\n",
      "sub-455219_ses-20190808T140448_behavior+ecephys+ogen.nwb\n",
      "left ALM          561\n",
      "left Thalamus     549\n",
      "right ALM         478\n",
      "right Midbrain    369\n",
      "Name: electrodes, dtype: int64\n",
      "sub-455219_ses-20190806T143015_behavior+ecephys+ogen.nwb\n",
      "left ALM          529\n",
      "right ALM         521\n",
      "left Thalamus     489\n",
      "right Midbrain    279\n",
      "Name: electrodes, dtype: int64\n",
      "456772\n",
      "sub-456772_ses-20191120T130334_behavior+ecephys+ogen.nwb\n",
      "left ALM          251\n",
      "left Midbrain     209\n",
      "right Midbrain    150\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191122T134226_behavior+ecephys+ogen.nwb\n",
      "right Thalamus    364\n",
      "left Thalamus     336\n",
      "right ALM         322\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191119T130822_behavior+ecephys+ogen.nwb\n",
      "right Midbrain    219\n",
      "left ALM          201\n",
      "left Midbrain     142\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191123T135013_behavior+ecephys+ogen.nwb\n",
      "left ALM          510\n",
      "right Striatum    245\n",
      "left Striatum     203\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191123T145127_behavior+ecephys+ogen.nwb\n",
      "left ALM          478\n",
      "left Striatum     378\n",
      "right Striatum    307\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191119T115109_behavior+ecephys+ogen.nwb\n",
      "left ALM          194\n",
      "right Midbrain    176\n",
      "left Midbrain     159\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191121T113844_behavior+ecephys+ogen.nwb\n",
      "right Thalamus    478\n",
      "left Thalamus     362\n",
      "right ALM         173\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191122T144855_behavior+ecephys+ogen.nwb\n",
      "right Thalamus    456\n",
      "left Thalamus     398\n",
      "right ALM         294\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191121T124405_behavior+ecephys+ogen.nwb\n",
      "left Thalamus     349\n",
      "right Thalamus    334\n",
      "right ALM          95\n",
      "Name: electrodes, dtype: int64\n",
      "sub-456772_ses-20191120T115527_behavior+ecephys+ogen.nwb\n",
      "left ALM          394\n",
      "left Midbrain     220\n",
      "right Midbrain    175\n",
      "Name: electrodes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def overview_units():\n",
    "    import os \n",
    "    path = '/Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata'\n",
    "    os.chdir(path)\n",
    "    sub_id = []\n",
    "    ses_id = []\n",
    "    for dir1 in os.listdir():\n",
    "        if not dir1.startswith('.'):\n",
    "            print(dir[4:])\n",
    "            sub_id+=[dir1]\n",
    "            os.chdir((path+'/'+dir1))\n",
    "            for file in (os.listdir()):\n",
    "                if not file.startswith('.'):\n",
    "                    print(file)\n",
    "                    ses_id+=[file[15:30]]\n",
    "                    ### load units and trials\n",
    "                    io = NWBHDF5IO(file, \"r\") \n",
    "                    nwbfile = io.read()\n",
    "                    units = nwbfile.units.to_dataframe()\n",
    "                    units_region = units.electrodes.apply(lambda x: ast.literal_eval(x.location.values[0])['brain_regions']).value_counts()\n",
    "                    print(units_region)\n",
    "overview_units()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "16a460fa-7737-4247-9b96-89ee46a256ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pooledandsegmented(units_Data, trials_Data):\n",
    "    \n",
    "#### get spikes with pooled and segmented trials between -3 and 3\n",
    "\n",
    "    '''\n",
    "    \n",
    "    spikes_pooled: all spikes from units_Data are pooled (no trial distinction)\n",
    "    spikes_segmented: spikes are segmented into trials, as defined by trials_Data\n",
    "    \n",
    "    time 0 represents the GO cue\n",
    "    each trial is defined by before<time<after\n",
    "    '''\n",
    "\n",
    "    after = 1.5\n",
    "    before = -2.5\n",
    "\n",
    "    spikes_pooled = []\n",
    "    spikes_segmented = []\n",
    "    for unit in units_Data.reset_index()['id']:\n",
    "        #print('unit', unit)\n",
    "        unit_spike_times = units_Data[\"spike_times\"][unit]\n",
    "        trial_spikes = []\n",
    "        spikes_pooled.append(unit_spike_times)\n",
    "        for index_time, time in enumerate(trials_Data['go_start'].values):\n",
    "            #print('time', time)\n",
    "            # Compute spike times relative to go signal\n",
    "            aligned_spikes = unit_spike_times - time\n",
    "            pre_go = time - trials_Data['pre_start'].values[index_time]\n",
    "            post_go = trials_Data['go_stop'].values[index_time]-time\n",
    "            #print('pre_go', pre_go)\n",
    "            #print('post_go', post_go)\n",
    "            aligned_spikes = aligned_spikes[aligned_spikes < after]\n",
    "            aligned_spikes = aligned_spikes[before < aligned_spikes]\n",
    "            trial_spikes.append(aligned_spikes)\n",
    "        spikes_segmented.append(trial_spikes)\n",
    "    print(\"shape pooled spikes\", np.shape(spikes_pooled))\n",
    "    print(\"shape segmented spikes\", np.shape(spikes_segmented))\n",
    "    return spikes_pooled, spikes_segmented\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ba44f285-f0c7-4546-99a8-306329617f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir sub-455219\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-455219\n",
      "datafile sub-455219_ses-20190805T152117_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (330,)\n",
      "shape segmented spikes (330, 392)\n",
      "session 20190805T152117\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190805T152117_behavior+ecephys+ogen.nwb\n",
      "\n",
      "shape pooled spikes (180,)\n",
      "shape segmented spikes (180, 392)\n",
      "session 20190805T152117\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190805T152117_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-455219/analysis\n",
      "datafile sub-455219_ses-20190807T134913_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (254,)\n",
      "shape segmented spikes (254, 477)\n",
      "session 20190807T134913\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190807T134913_behavior+ecephys+ogen.nwb\n",
      "\n",
      "shape pooled spikes (437,)\n",
      "shape segmented spikes (437, 477)\n",
      "session 20190807T134913\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190807T134913_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-455219/analysis\n",
      "datafile sub-455219_ses-20190808T140448_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (406,)\n",
      "shape segmented spikes (406, 581)\n",
      "session 20190808T140448\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190808T140448_behavior+ecephys+ogen.nwb\n",
      "\n",
      "shape pooled spikes (299,)\n",
      "shape segmented spikes (299, 581)\n",
      "session 20190808T140448\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190808T140448_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-455219/analysis\n",
      "datafile sub-455219_ses-20190806T143015_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (318,)\n",
      "shape segmented spikes (318, 449)\n",
      "session 20190806T143015\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190806T143015_behavior+ecephys+ogen.nwb\n",
      "\n",
      "shape pooled spikes (274,)\n",
      "shape segmented spikes (274, 449)\n",
      "session 20190806T143015\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-455219_ses-20190806T143015_behavior+ecephys+ogen.nwb\n",
      "\n",
      "dir sub-456772\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772\n",
      "datafile sub-456772_ses-20191120T130334_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (103,)\n",
      "shape segmented spikes (103, 268)\n",
      "session 20191120T130334\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191120T130334_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191122T134226_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (175,)\n",
      "shape segmented spikes (175, 370)\n",
      "session 20191122T134226\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191122T134226_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191119T130822_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (100,)\n",
      "shape segmented spikes (100, 252)\n",
      "session 20191119T130822\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191119T130822_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191123T135013_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (314,)\n",
      "shape segmented spikes (314, 333)\n",
      "session 20191123T135013\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191123T135013_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191123T145127_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (274,)\n",
      "shape segmented spikes (274, 485)\n",
      "session 20191123T145127\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191123T145127_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191119T115109_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (93,)\n",
      "shape segmented spikes (93, 296)\n",
      "session 20191119T115109\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191119T115109_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191121T113844_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (90,)\n",
      "shape segmented spikes (90, 381)\n",
      "session 20191121T113844\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191121T113844_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191122T144855_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (160,)\n",
      "shape segmented spikes (160, 225)\n",
      "session 20191122T144855\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191122T144855_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191121T124405_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (45,)\n",
      "shape segmented spikes (45, 384)\n",
      "session 20191121T124405\n",
      "region right ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191121T124405_behavior+ecephys+ogen.nwb\n",
      "\n",
      "working directory /Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/sub-456772/analysis\n",
      "datafile sub-456772_ses-20191120T115527_behavior+ecephys+ogen.nwb\n",
      "shape pooled spikes (223,)\n",
      "shape segmented spikes (223, 294)\n",
      "session 20191120T115527\n",
      "region left ALM\n",
      "<class 'str'>\n",
      "export complete for file  sub-456772_ses-20191120T115527_behavior+ecephys+ogen.nwb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_stats(trials_Data):\n",
    "    ##### get stats to calculate selectivity\n",
    "    trials_hit = trials_Data.query(\"outcome=='hit'\").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'early_lick':'no early'}&{'outcome':'hit'}).fetch('trial'))\n",
    "    trials_miss = trials_Data.query(\"outcome=='miss'\").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'early_lick':'no early'}&{'outcome':'miss'}).fetch('trial'))\n",
    "    trials_ignore = trials_Data.query(\"outcome=='ignore'\").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'outcome':'ignore'}).fetch('trial'))\n",
    "    trials_early = trials_Data.query(\"early_lick=='early'\").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'early_lick':'early'}).fetch('trial'))\n",
    "    left_hit =  trials_Data.query(\"trial_instruction=='left' and outcome=='hit' \").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'early_lick':'no early'}&{'outcome':'hit'}&{'trial_instruction':'left'}).fetch('trial'))\n",
    "    right_hit = trials_Data.query(\"trial_instruction=='right' and outcome=='hit' \").trial.values.astype(\"float\")#np.unique((units_subject_ALM_session&{'early_lick':'no early'}&{'outcome':'hit'}&{'trial_instruction':'right'}).fetch('trial'))\n",
    "\n",
    "    hit = len(trials_hit)\n",
    "    miss = len(trials_miss)\n",
    "    ignore = len(trials_ignore)\n",
    "    early = len(trials_early)\n",
    "    combinedtrials = trials_Data.trial.values.astype(\"float\")\n",
    "    '''print('hit', hit)\n",
    "    print('miss',miss)\n",
    "    print('ignore', ignore)\n",
    "    print('early', early)\n",
    "    print('percentcorrect', hit/(hit+miss))\n",
    "    print('left_trials', len(left_hit))\n",
    "    print('right_trials', len(right_hit))\n",
    "    '''\n",
    "    stats = [hit, miss, ignore, early, combinedtrials, left_hit, right_hit]\n",
    "    return stats\n",
    "\n",
    "def export_neuraldata(spikes_pooled, spikes_segmented,region, *idparams):\n",
    "    import os\n",
    "    import pickle\n",
    "    sub_id, session_id = idparams \n",
    "    path = '/Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/'+'sub-'+str(sub_id)+'/analysis'\n",
    "    os.chdir(path)\n",
    "    ###### EXPORT DATA##########\n",
    "    with open(str(region)+'_notrials'+'sub-'+str(sub_id)+'_ses-'+str(session_id)+'_allunits.pkl', 'wb') as f:  # open a text file\n",
    "        pickle.dump(spikes_pooled, f) # \n",
    "    with open(region+'_withtrials'+'sub-'+str(sub_id)+'_ses-'+str(session_id)+'_allunits.pkl', 'wb') as f:  # open a text file\n",
    "        pickle.dump(spikes_segmented, f) # \n",
    "\n",
    "def export_stats(stats,*idparams):\n",
    "    import os\n",
    "    import pickle\n",
    "    sub_id, session_id = idparams \n",
    "    path = '/Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata/'+'sub-'+str(sub_id)+'/analysis'\n",
    "    os.chdir(path)\n",
    "    ###### EXPORT DATA##########\n",
    "    with open('session'+str(session_id)+'_sub'+str(sub_id)+'_stats.pkl', 'wb') as f: \n",
    "         pickle.dump(stats, f) # \n",
    "\n",
    "\n",
    "def get_data_allfiles(regions):\n",
    "    \n",
    "    '''\n",
    "    Main function. It exports data related to statistics (e.g., hit, miss, etc.), spikes_pooled, spikes_segmented\n",
    "\n",
    "    Input\n",
    "    \n",
    "    regions: set of regions to get the units data from\n",
    "    \n",
    "    '''\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import os \n",
    "    path = '/Users/jaramillo/map-ephys/notebook/workshop/April2024NWB/NWBdata'\n",
    "    os.chdir(path) \n",
    "    for dir1 in os.listdir():\n",
    "        if not dir1.startswith('.'):\n",
    "            print('dir', dir1)\n",
    "            sub_id = dir1[4:]\n",
    "            os.chdir((path+'/'+dir1))\n",
    "            for file in (os.listdir()):\n",
    "                if  file.endswith(\".nwb\"):\n",
    "                    session_id= file[15:30]\n",
    "                    datafile = file\n",
    "                    print('working directory', os.getcwd())\n",
    "                    print('datafile', datafile)\n",
    "                    ### load NWB data\n",
    "                    os.chdir((path+'/'+dir1))\n",
    "                    io = NWBHDF5IO(datafile, \"r\") \n",
    "                    nwbfile = io.read()\n",
    "                    ### load units and trials\n",
    "                    units = nwbfile.units.to_dataframe()\n",
    "                    alltrials = nwbfile.trials.to_dataframe()\n",
    "                    alltrials_clean = Clean_data(file, alltrials)\n",
    "                    trials_Data = select_trials(alltrials_clean)\n",
    "                    stats = get_stats(trials_Data)\n",
    "                    idparams = sub_id, session_id\n",
    "                    export_stats(stats, *idparams)\n",
    "                    for region in regions:\n",
    "                        units_Data = select_units(units, region)\n",
    "                        if units_Data.empty==False:\n",
    "                            spikes_pooled, spikes_segmented = get_pooledandsegmented(units_Data, trials_Data)\n",
    "                            print('session', session_id)\n",
    "                            print('region',region)\n",
    "                            print(type(region))\n",
    "                            export_neuraldata(spikes_pooled, spikes_segmented,region, *idparams)\n",
    "                            print('export complete for file ', file)\n",
    "                            print()\n",
    "get_data_allfiles(['left ALM', 'right ALM'])\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b16fe564-c657-422e-92e0-f906bb1c41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####OLD\n",
    "####EXPORT units with all trials pooled, segmented and stats\n",
    "\n",
    "### load NWB data\n",
    "io = NWBHDF5IO(file, \"r\") \n",
    "nwbfile = io.read()\n",
    "### load units and trials\n",
    "units = nwbfile.units.to_dataframe()\n",
    "alltrials = nwbfile.trials.to_dataframe()\n",
    "\n",
    "alltrials_clean = Clean_data(file)\n",
    "units_Data, trials_Data = selectunitsandtrials(units, alltrials_clean)\n",
    "###### EXPORT DATA##########\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('unitsALM_notrials'+'sub-'+str(sub_id)+'_ses-'+str(session_id)+'_allunits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(spikes_pooled, f) # \n",
    "with open('unitsALM_withtrials'+'sub-'+str(sub_id)+'_ses-'+str(session_id)+'_allunits.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(spikes_segmented, f) # \n",
    "#with open('unitsThal_notrials_session'+str(session_id)+'_sub'+str(sub_id)+'_allunits.pkl', 'wb') as f:  # open a text file\n",
    "    #pickle.dump(spikes_pooled_th, f) \n",
    "with open('session'+str(session_id)+'_sub'+str(sub_id)+'_stats.pkl', 'wb') as f: \n",
    "     pickle.dump(stats, f) # \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
